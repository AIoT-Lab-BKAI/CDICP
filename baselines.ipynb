{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file: ./data/distributed/sachs/m3_d1_n10/silo-0.csv\t10000  Instances\t 11 Variables\n",
      "Loaded file: ./data/distributed/sachs/m3_d1_n10/silo-1.csv\t10000  Instances\t 11 Variables\n",
      "Loaded file: ./data/distributed/sachs/m3_d1_n10/silo-2.csv\t10000  Instances\t 11 Variables\n",
      "Loaded file: ./data/distributed/sachs/m3_d1_n10/silo-3.csv\t10000  Instances\t 11 Variables\n",
      "Loaded file: ./data/distributed/sachs/m3_d1_n10/silo-4.csv\t10000  Instances\t 11 Variables\n",
      "Loaded file: ./data/distributed/sachs/m3_d1_n10/silo-5.csv\t10000  Instances\t 11 Variables\n",
      "Loaded file: ./data/distributed/sachs/m3_d1_n10/silo-6.csv\t10000  Instances\t 11 Variables\n",
      "Loaded file: ./data/distributed/sachs/m3_d1_n10/silo-7.csv\t10000  Instances\t 11 Variables\n",
      "Loaded file: ./data/distributed/sachs/m3_d1_n10/silo-8.csv\t10000  Instances\t 11 Variables\n",
      "Loaded file: ./data/distributed/sachs/m3_d1_n10/silo-9.csv\t10000  Instances\t 11 Variables\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "\n",
    "dataname = \"sachs\"\n",
    "groundtruth = np.array(json.load(open(f\"../CausalBKAI/data/TestData/bnlearn_discrete_10000/truth_dag_adj/{dataname}.json\", \"r\"))['Adj'])\n",
    "\n",
    "mi = 3      # The number of values a variable can take is ranged in [2, mi-1]\n",
    "di = 1      # The dirichlet alpha that controls the data distribution\n",
    "n = 10      # The number of data silos\n",
    "\n",
    "silos = []\n",
    "\n",
    "folderpath = f\"./data/distributed/{dataname}/m{mi}_d{di}_n{n}\"\n",
    "\n",
    "if not Path(folderpath).exists():\n",
    "    print(\"Folder\", folderpath, \"not exist!\")\n",
    "else:\n",
    "    for file in sorted(os.listdir(folderpath)):\n",
    "        filename = os.path.join(folderpath, file)\n",
    "        silo_data = pd.read_csv(filename)\n",
    "        silos.append(silo_data)\n",
    "        print(\"Loaded file:\", filename, end=\"\\t\")\n",
    "        all_vars = silos[0].columns\n",
    "        print(len(silo_data), \" Instances\\t\", len(all_vars), \"Variables\")\n",
    "        \n",
    "\n",
    "merged_df = pd.concat(silos, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constraint-based PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d671e513949248ac88dce2e4a1840f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[datazets] >INFO> Reached maximum number of allowed conditional variables. Exiting\n",
      "[datazets] >WARNING> PDAG has no faithful extension (= no oriented DAG with the same v-structures as PDAG). Remaining undirected PDAG edges oriented arbitrarily.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e21a708b0654138aac2d73617b2690a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[datazets] >INFO> Reached maximum number of allowed conditional variables. Exiting\n",
      "[datazets] >WARNING> PDAG has no faithful extension (= no oriented DAG with the same v-structures as PDAG). Remaining undirected PDAG edges oriented arbitrarily.\n"
     ]
    }
   ],
   "source": [
    "import bnlearn as bn\n",
    "\n",
    "model = bn.structure_learning.fit(merged_df, methodtype='cs', verbose=0)\n",
    "\n",
    "adj_mtx = np.zeros([len(all_vars), len(all_vars)])\n",
    "for edge in model['dag_edges']:     # type:ignore\n",
    "    source, target = edge\n",
    "    source_id = int(source[1:]) - 1\n",
    "    target_id = int(target[1:]) - 1\n",
    "    adj_mtx[source_id][target_id] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0 2 9\n"
     ]
    }
   ],
   "source": [
    "from plot_utils import true_edge, spur_edge, fals_edge, miss_edge, swap_pos\n",
    "\n",
    "etrue = true_edge(groundtruth, adj_mtx)\n",
    "espur = spur_edge(groundtruth, adj_mtx)\n",
    "efals = fals_edge(groundtruth, adj_mtx)\n",
    "emiss = miss_edge(groundtruth, adj_mtx)\n",
    "\n",
    "# print(etrue)\n",
    "print(len(etrue), len(espur), len(emiss), len(efals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causal discovery from nonstationary/heterogeneous data (CDNOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0e0cac1b2349e08336b16bb2df1bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from causallearn.search.ConstraintBased.CDNOD import cdnod\n",
    "from baselines.FL_FedCDH.mycausallearn.utils.data_utils import get_cpdag_from_cdnod, get_dag_from_pdag\n",
    "from causallearn.utils.cit import fisherz\n",
    "\n",
    "c_indx = []\n",
    "for i in range(len(silos)):\n",
    "    data = silos[i]\n",
    "    c_indx += [i+1] * len(data)\n",
    "c_indx = np.array(c_indx).reshape(len(silos)*len(silos[0]), 1)\n",
    "\n",
    "cg = cdnod(merged_df.to_numpy(), c_indx, 0.05, fisherz)\n",
    "\n",
    "est_graph = cg.G.graph[0:len(all_vars), 0:len(all_vars)]\n",
    "est_cpdag = get_cpdag_from_cdnod(est_graph) # est_graph[i,j]=-1 & est_graph[j,i]=1  ->  est_graph_cpdag[i,j]=1\n",
    "est_dag_from_pdag = get_dag_from_pdag(est_cpdag) # return a DAG from a PDAG in causaldag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 13 10 2\n"
     ]
    }
   ],
   "source": [
    "from plot_utils import true_edge, spur_edge, fals_edge, miss_edge\n",
    "\n",
    "etrue = true_edge(groundtruth, est_dag_from_pdag)\n",
    "espur = spur_edge(groundtruth, est_dag_from_pdag)\n",
    "efals = fals_edge(groundtruth, est_dag_from_pdag)\n",
    "emiss = miss_edge(groundtruth, est_dag_from_pdag)\n",
    "\n",
    "# print(etrue)\n",
    "print(len(etrue), len(espur), len(emiss), len(efals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constraint-based Fast Causal Inference (FCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8cacb322ce4d05ba4f2888fc2a3337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X6 --> X3\n",
      "X3 --> X7\n",
      "X3 --> X9\n",
      "X3 --> X11\n",
      "X12 --> X3\n",
      "X6 --> X7\n",
      "X9 --> X6\n",
      "X11 --> X6\n",
      "X12 --> X6\n",
      "X6 --> X16\n",
      "X9 --> X7\n",
      "X11 --> X7\n",
      "X12 --> X7\n",
      "X11 --> X9\n",
      "X9 --> X12\n",
      "X9 --> X17\n",
      "X9 --> X18\n",
      "X12 --> X19\n",
      "X14 --> X20\n",
      "X14 --> X21\n",
      "X15 --> X36\n",
      "X16 --> X31\n",
      "X16 --> X37\n",
      "X18 --> X30\n",
      "X22 --> X23\n",
      "X26 --> X27\n",
      "X26 --> X28\n",
      "X27 --> X30\n",
      "X28 --> X29\n",
      "X28 --> X31\n",
      "X32 --> X35\n"
     ]
    }
   ],
   "source": [
    "from causallearn.search.ConstraintBased.FCI import fci\n",
    "\n",
    "# default parameters\n",
    "g, edges = fci(merged_df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for edge in edges:\n",
    "#     print(edge, \"\\t\", edge.get_node1(), edge.get_numerical_endpoint1(), edge.get_node2(), edge.get_numerical_endpoint2())\n",
    "\n",
    "adj_mtx = np.zeros([len(all_vars), len(all_vars)])\n",
    "for edge in edges:     # type:ignore\n",
    "    source_id = int(edge.get_node1().get_name()[1:]) - 1\n",
    "    target_id = int(edge.get_node2().get_name()[1:]) - 1\n",
    "    \n",
    "    if edge.get_numerical_endpoint1() == -1:\n",
    "        adj_mtx[source_id][target_id] = 1\n",
    "    elif edge.get_numerical_endpoint1() != 2:\n",
    "        adj_mtx[target_id][source_id] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 61 34 8\n"
     ]
    }
   ],
   "source": [
    "from plot_utils import true_edge, spur_edge, fals_edge, miss_edge, swap_pos\n",
    "\n",
    "etrue = true_edge(groundtruth, adj_mtx)\n",
    "espur = spur_edge(groundtruth, adj_mtx)\n",
    "efals = fals_edge(groundtruth, adj_mtx)\n",
    "emiss = miss_edge(groundtruth, adj_mtx)\n",
    "\n",
    "# print(etrue)\n",
    "print(len(etrue), len(espur), len(emiss), len(efals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value-based HillClimb GES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnlearn as bn\n",
    "\n",
    "model = bn.structure_learning.fit(merged_df, methodtype='hc', verbose=0)\n",
    "adj_mtx = model['adjmat'].to_numpy() * 1.0      # type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 103 70 10\n"
     ]
    }
   ],
   "source": [
    "from plot_utils import true_edge, spur_edge, fals_edge, miss_edge\n",
    "\n",
    "etrue = true_edge(groundtruth, adj_mtx.T)\n",
    "espur = spur_edge(groundtruth, adj_mtx.T)\n",
    "efals = fals_edge(groundtruth, adj_mtx.T)\n",
    "emiss = miss_edge(groundtruth, adj_mtx.T)\n",
    "\n",
    "# print(etrue)\n",
    "print(len(etrue), len(espur), len(emiss), len(efals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value-based Treesearch Chow-Liu Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnlearn as bn\n",
    "# Preprocessing raw dataset\n",
    "dfhot, dfnum = bn.df2onehot(merged_df)\n",
    "\n",
    "# Structure learning\n",
    "model = bn.structure_learning.fit(dfnum, methodtype='cl', verbose=0)\n",
    "adj_mtx = model['adjmat'].to_numpy() * 1.0      # type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils import true_edge, spur_edge, fals_edge, miss_edge\n",
    "\n",
    "etrue = true_edge(groundtruth, adj_mtx)\n",
    "espur = spur_edge(groundtruth, adj_mtx)\n",
    "efals = fals_edge(groundtruth, adj_mtx)\n",
    "emiss = miss_edge(groundtruth, adj_mtx)\n",
    "\n",
    "# print(etrue)\n",
    "print(len(etrue), len(espur), len(emiss), len(efals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value-based Tree-augmented Naive Bayes (TAN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnlearn as bn\n",
    "\n",
    "# Structure learning\n",
    "model = bn.structure_learning.fit(merged_df, methodtype='tan', class_node='X1', verbose=0)\n",
    "pruned_model = bn.independence_test(model, merged_df, alpha=0.05, prune=True)\n",
    "\n",
    "adj_mtx = pruned_model['adjmat'].to_numpy() * 1.0      # type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils import true_edge, spur_edge, fals_edge, miss_edge\n",
    "\n",
    "etrue = true_edge(groundtruth, adj_mtx)\n",
    "espur = spur_edge(groundtruth, adj_mtx)\n",
    "efals = fals_edge(groundtruth, adj_mtx)\n",
    "emiss = miss_edge(groundtruth, adj_mtx)\n",
    "\n",
    "# print(etrue)\n",
    "print(len(etrue), len(espur), len(emiss), len(efals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDT.CAUSALITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concave penalized Coordinate Descent with reparametrization (CCDR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdt.causality.graph import CCDr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy Interventional Equivalence Search algorithm (GIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdt.causality.graph import GIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structural Agnostic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdt.causality.graph import SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Causal Generative Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdt.causality.graph import CGNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyFL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
